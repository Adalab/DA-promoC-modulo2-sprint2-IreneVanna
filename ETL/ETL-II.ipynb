{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pair Programming ETL II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tendréis que usar el csv attacks_limpieza_completa que tenéis adjunto abajo.\n",
    "En la lección de hoy aprendimos como transformar nuestros datos para que estén preparados para almacearlos en una BBDD. En este momento tenemos dos fuentes de datos:\n",
    "1. El csv con los ataques de tiburones que hemos estado limpiando hasta ahora, el que os hemos adjuntado (attacks_limpieza_completa). Sentiros libres de usar vuestros propios csv en caso de que queráis.\n",
    "2. El csv con los datos climáticos de los principales paises que tienen ataques de tiburones, el que creamos en el pair programming de ayer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de la sesión de hoy será juntar en un único csv la información de ambas fuentes. Para ello:\n",
    "- Cargaremos los dos ficheros de datos\n",
    "- Del dataframe de los ataques nos quedaremos solo con las filas de los países que seleccionamos en la lección de ayer:\n",
    "    -  USA\n",
    "    -  Australia\n",
    "    -  New Zealand\n",
    "    -  South Africa\n",
    "    -  Papua New Guinea\n",
    "- Del dataframe de los datos climáticos seleccionaremos todas las columnas.\n",
    "- Cuando ya tengamos todos los datos deseados juntaremos los dos csv.\n",
    "    - Para hacer esta unión tendremos que hacer un groupby en la tabla de clima para sacar una media de las medidas climáticas por país.\n",
    "    - Antes de hacer el groupby si nos fijamos tenemos dos columnas rh_profile y wind_profile cuya información es una lista de diccionarios. Si intentamos hacer la media de eso no nos dará un valor real. A este problema ya nos enfrentamos en la clase invertida de ETL-2, donde teníais un Bonus para desempaquetar esta información. En caso de que en aquel ejercicio no lo consigierais os dejamos por aquí una posible solución que nos permite separar esa información en distintas columnas. Os dejamos el código documentado. ⚠️ Os recomendamos que vayáis desgranando el código y viendo lo que nos devuelve cada línea de código para entenderlo mejor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell \n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attack = pd.read_csv(\"../datos/datos_limpiezaV.csv\", index_col=0)\n",
    "df_clima = pd.read_csv(\"../datos/datos_clima.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timepoint</th>\n",
       "      <th>cloudcover</th>\n",
       "      <th>highcloud</th>\n",
       "      <th>midcloud</th>\n",
       "      <th>lowcloud</th>\n",
       "      <th>rh_profile</th>\n",
       "      <th>wind_profile</th>\n",
       "      <th>temp2m</th>\n",
       "      <th>lifted_index</th>\n",
       "      <th>rh2m</th>\n",
       "      <th>msl_pressure</th>\n",
       "      <th>prec_type</th>\n",
       "      <th>prec_amount</th>\n",
       "      <th>snow_depth</th>\n",
       "      <th>wind10m.direction</th>\n",
       "      <th>wind10m.speed</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>[{'layer': '950mb', 'rh': 10}, {'layer': '900m...</td>\n",
       "      <td>[{'layer': '950mb', 'direction': 175, 'speed':...</td>\n",
       "      <td>27</td>\n",
       "      <td>-4</td>\n",
       "      <td>10</td>\n",
       "      <td>-9999</td>\n",
       "      <td>rain</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>2</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>[{'layer': '950mb', 'rh': 11}, {'layer': '900m...</td>\n",
       "      <td>[{'layer': '950mb', 'direction': 195, 'speed':...</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>10</td>\n",
       "      <td>-9999</td>\n",
       "      <td>rain</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>[{'layer': '950mb', 'rh': 11}, {'layer': '900m...</td>\n",
       "      <td>[{'layer': '950mb', 'direction': 180, 'speed':...</td>\n",
       "      <td>27</td>\n",
       "      <td>-1</td>\n",
       "      <td>10</td>\n",
       "      <td>-9999</td>\n",
       "      <td>rain</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>2</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>[{'layer': '950mb', 'rh': 11}, {'layer': '900m...</td>\n",
       "      <td>[{'layer': '950mb', 'direction': 180, 'speed':...</td>\n",
       "      <td>27</td>\n",
       "      <td>-1</td>\n",
       "      <td>11</td>\n",
       "      <td>-9999</td>\n",
       "      <td>rain</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>3</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>[{'layer': '950mb', 'rh': 13}, {'layer': '900m...</td>\n",
       "      <td>[{'layer': '950mb', 'direction': 185, 'speed':...</td>\n",
       "      <td>27</td>\n",
       "      <td>-1</td>\n",
       "      <td>11</td>\n",
       "      <td>-9999</td>\n",
       "      <td>rain</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>185</td>\n",
       "      <td>3</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timepoint  cloudcover  highcloud  midcloud  lowcloud  \\\n",
       "0          3           8      -9999     -9999     -9999   \n",
       "1          6           9      -9999     -9999     -9999   \n",
       "2          9           9      -9999     -9999     -9999   \n",
       "3         12           7      -9999     -9999     -9999   \n",
       "4         15           6      -9999     -9999     -9999   \n",
       "\n",
       "                                          rh_profile  \\\n",
       "0  [{'layer': '950mb', 'rh': 10}, {'layer': '900m...   \n",
       "1  [{'layer': '950mb', 'rh': 11}, {'layer': '900m...   \n",
       "2  [{'layer': '950mb', 'rh': 11}, {'layer': '900m...   \n",
       "3  [{'layer': '950mb', 'rh': 11}, {'layer': '900m...   \n",
       "4  [{'layer': '950mb', 'rh': 13}, {'layer': '900m...   \n",
       "\n",
       "                                        wind_profile  temp2m  lifted_index  \\\n",
       "0  [{'layer': '950mb', 'direction': 175, 'speed':...      27            -4   \n",
       "1  [{'layer': '950mb', 'direction': 195, 'speed':...      26            -1   \n",
       "2  [{'layer': '950mb', 'direction': 180, 'speed':...      27            -1   \n",
       "3  [{'layer': '950mb', 'direction': 180, 'speed':...      27            -1   \n",
       "4  [{'layer': '950mb', 'direction': 185, 'speed':...      27            -1   \n",
       "\n",
       "   rh2m  msl_pressure prec_type  prec_amount  snow_depth  wind10m.direction  \\\n",
       "0    10         -9999      rain            2           0                150   \n",
       "1    10         -9999      rain            2           0                160   \n",
       "2    10         -9999      rain            3           0                180   \n",
       "3    11         -9999      rain            3           0                180   \n",
       "4    11         -9999      rain            3           0                185   \n",
       "\n",
       "   wind10m.speed country  \n",
       "0              2     usa  \n",
       "1              1     usa  \n",
       "2              2     usa  \n",
       "3              3     usa  \n",
       "4              3     usa  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clima.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>country</th>\n",
       "      <th>age</th>\n",
       "      <th>species</th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>fatal</th>\n",
       "      <th>sex</th>\n",
       "      <th>main_species</th>\n",
       "      <th>age_numbers</th>\n",
       "      <th>age_numbers_mean</th>\n",
       "      <th>sex_moda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018.0</td>\n",
       "      <td>usa</td>\n",
       "      <td>57</td>\n",
       "      <td>White shark</td>\n",
       "      <td>25-Jun-2018</td>\n",
       "      <td>Jun</td>\n",
       "      <td>n</td>\n",
       "      <td>F</td>\n",
       "      <td>white_shark</td>\n",
       "      <td>57.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018.0</td>\n",
       "      <td>brazil</td>\n",
       "      <td>18</td>\n",
       "      <td>Tiger shark</td>\n",
       "      <td>03-Jun-2018</td>\n",
       "      <td>Jun</td>\n",
       "      <td>y</td>\n",
       "      <td>M</td>\n",
       "      <td>tiger_shark</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018.0</td>\n",
       "      <td>usa</td>\n",
       "      <td>15</td>\n",
       "      <td>Bull shark, 6'</td>\n",
       "      <td>26-May-2018</td>\n",
       "      <td>May</td>\n",
       "      <td>n</td>\n",
       "      <td>M</td>\n",
       "      <td>bull_shark</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018.0</td>\n",
       "      <td>australia</td>\n",
       "      <td>32</td>\n",
       "      <td>Grey reef shark</td>\n",
       "      <td>24-May-2018</td>\n",
       "      <td>May</td>\n",
       "      <td>n</td>\n",
       "      <td>M</td>\n",
       "      <td>grey_shark</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018.0</td>\n",
       "      <td>england</td>\n",
       "      <td>21</td>\n",
       "      <td>Invalid incident</td>\n",
       "      <td>13-May-2018</td>\n",
       "      <td>May</td>\n",
       "      <td>n</td>\n",
       "      <td>M</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     year    country age           species         date month fatal sex  \\\n",
       "0  2018.0        usa  57       White shark  25-Jun-2018   Jun     n   F   \n",
       "1  2018.0     brazil  18       Tiger shark  03-Jun-2018   Jun     y   M   \n",
       "2  2018.0        usa  15    Bull shark, 6'  26-May-2018   May     n   M   \n",
       "3  2018.0  australia  32   Grey reef shark  24-May-2018   May     n   M   \n",
       "4  2018.0    england  21  Invalid incident  13-May-2018   May     n   M   \n",
       "\n",
       "  main_species  age_numbers  age_numbers_mean sex_moda  \n",
       "0  white_shark         57.0              57.0        F  \n",
       "1  tiger_shark         18.0              18.0        M  \n",
       "2   bull_shark         15.0              15.0        M  \n",
       "3   grey_shark         32.0              32.0        M  \n",
       "4  unspecified         21.0              21.0        M  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_attack.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>country</th>\n",
       "      <th>age</th>\n",
       "      <th>species</th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>fatal</th>\n",
       "      <th>sex</th>\n",
       "      <th>main_species</th>\n",
       "      <th>age_numbers</th>\n",
       "      <th>age_numbers_mean</th>\n",
       "      <th>sex_moda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018.0</td>\n",
       "      <td>usa</td>\n",
       "      <td>57</td>\n",
       "      <td>White shark</td>\n",
       "      <td>25-Jun-2018</td>\n",
       "      <td>Jun</td>\n",
       "      <td>n</td>\n",
       "      <td>F</td>\n",
       "      <td>white_shark</td>\n",
       "      <td>57.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018.0</td>\n",
       "      <td>usa</td>\n",
       "      <td>15</td>\n",
       "      <td>Bull shark, 6'</td>\n",
       "      <td>26-May-2018</td>\n",
       "      <td>May</td>\n",
       "      <td>n</td>\n",
       "      <td>M</td>\n",
       "      <td>bull_shark</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018.0</td>\n",
       "      <td>australia</td>\n",
       "      <td>32</td>\n",
       "      <td>Grey reef shark</td>\n",
       "      <td>24-May-2018</td>\n",
       "      <td>May</td>\n",
       "      <td>n</td>\n",
       "      <td>M</td>\n",
       "      <td>grey_shark</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018.0</td>\n",
       "      <td>australia</td>\n",
       "      <td>60</td>\n",
       "      <td>3 m shark</td>\n",
       "      <td>25-Apr-2018</td>\n",
       "      <td>Apr</td>\n",
       "      <td>n</td>\n",
       "      <td>M</td>\n",
       "      <td>unspecified</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018.0</td>\n",
       "      <td>south africa</td>\n",
       "      <td>33</td>\n",
       "      <td>White shark, 2.5 m</td>\n",
       "      <td>22-Apr-2018</td>\n",
       "      <td>Apr</td>\n",
       "      <td>n</td>\n",
       "      <td>M</td>\n",
       "      <td>white_shark</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     year       country age             species         date month fatal sex  \\\n",
       "0  2018.0           usa  57         White shark  25-Jun-2018   Jun     n   F   \n",
       "2  2018.0           usa  15      Bull shark, 6'  26-May-2018   May     n   M   \n",
       "3  2018.0     australia  32     Grey reef shark  24-May-2018   May     n   M   \n",
       "6  2018.0     australia  60           3 m shark  25-Apr-2018   Apr     n   M   \n",
       "8  2018.0  south africa  33  White shark, 2.5 m  22-Apr-2018   Apr     n   M   \n",
       "\n",
       "  main_species  age_numbers  age_numbers_mean sex_moda  \n",
       "0  white_shark         57.0              57.0        F  \n",
       "2   bull_shark         15.0              15.0        M  \n",
       "3   grey_shark         32.0              32.0        M  \n",
       "6  unspecified         60.0              60.0        M  \n",
       "8  white_shark         33.0              33.0        M  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attaques = df_attack[(df_attack[\"country\"] == \"usa\") | (df_attack[\"country\"] == \"australia\") | (df_attack[\"country\"] == \"papua new guinea\") | (df_attack[\"country\"] == \"new zealand\")| (df_attack[\"country\"] == \"south africa\")]\n",
    "attaques.head()\n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clima.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import ast\n",
    "\n",
    "df_clima['rh_profile']= df_clima['rh_profile'].apply(ast.literal_eval)\n",
    "\n",
    "# una vez que tengamos la columna cambiada, una fantasía de Pandas es que si hago un apply sobre una columna cuyos valores son diccionarios o listas nos va a genererar una columna con los valores de los diccionarios o listas. Donde cada columna será key del diccionario o cada elemento de la lista. \n",
    "\n",
    "\n",
    "#x = df_clima['wind_profile'].apply(pd.Series)\n",
    "\n",
    "\n",
    "# nos creamos un dataframe nuevo con el resultado de la información de una de las columnas separadas por columnas. Esto nos va a devolver un dataframe donde cada fila será una celda del dataframe anterior. \n",
    "x = df_clima['rh_profile'].apply(pd.Series) \n",
    "\n",
    "# ¿Qué es lo que ocurre cuando hacemos esto?\n",
    "# Nos ha creado tantas columnas como valores tuvieramos en la lista. Donde columna es, en este caso, un diccionario (porque nuestra lista esta compuesta por distintos diccionarios)\n",
    "\n",
    "# Ok, hemos conseguido desempaquetar la información de la lista en distintas columnas. Ahora tenemos que despempaquetar la información de los diccionarios en distintas columnas. En este caso, lo que querremos es que las key de los diccionarios sean los nombres de las columnas y los values los valores de las celdas del dataframe. Volveremos a seguir entonces la misma lógica que antes con el apply, pero en este caso necesitamos hacerlo para todo el dataframe (que es x): \n",
    "\n",
    "# Por eso empezamos con un for para iterar por cada una de las columnas. \n",
    "for i in range(len(x.columns)): \n",
    "\n",
    "    # aplicamos el apply,extraemos el valore de la key \"layer\" y lo almacenamos en una variable que convertimos a string \n",
    "    nombre = \"rh_\" + str(x[i].apply(pd.Series)[\"layer\"][0]) \n",
    "\n",
    "    # hacemos lo mismo con una variable que se llame valores para \"guardar\" los valores de la celda\n",
    "    valores = list(x[i].apply(pd.Series)[\"rh\"] )\n",
    "\n",
    "    # usamos el método insert de los dataframes para ir añadiendo esta información a el dataframe con la información del clima. \n",
    "    df_clima.insert(i, nombre, valores)\n",
    "\n",
    "# una vez que hayamos hecho esto para las dos columnas ya podremos hacer el gropuby para después unir toda la información. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rh_950mb</th>\n",
       "      <th>rh_900mb</th>\n",
       "      <th>rh_850mb</th>\n",
       "      <th>rh_800mb</th>\n",
       "      <th>rh_750mb</th>\n",
       "      <th>rh_700mb</th>\n",
       "      <th>rh_650mb</th>\n",
       "      <th>rh_600mb</th>\n",
       "      <th>rh_550mb</th>\n",
       "      <th>rh_500mb</th>\n",
       "      <th>rh_450mb</th>\n",
       "      <th>rh_400mb</th>\n",
       "      <th>rh_350mb</th>\n",
       "      <th>rh_300mb</th>\n",
       "      <th>rh_250mb</th>\n",
       "      <th>rh_200mb</th>\n",
       "      <th>index</th>\n",
       "      <th>timepoint</th>\n",
       "      <th>cloudcover</th>\n",
       "      <th>highcloud</th>\n",
       "      <th>midcloud</th>\n",
       "      <th>lowcloud</th>\n",
       "      <th>rh_profile</th>\n",
       "      <th>wind_profile</th>\n",
       "      <th>temp2m</th>\n",
       "      <th>lifted_index</th>\n",
       "      <th>rh2m</th>\n",
       "      <th>msl_pressure</th>\n",
       "      <th>prec_type</th>\n",
       "      <th>prec_amount</th>\n",
       "      <th>snow_depth</th>\n",
       "      <th>wind10m.direction</th>\n",
       "      <th>wind10m.speed</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>[{'layer': '950mb', 'rh': 10}, {'layer': '900m...</td>\n",
       "      <td>[{'layer': '950mb', 'direction': 175, 'speed':...</td>\n",
       "      <td>27</td>\n",
       "      <td>-4</td>\n",
       "      <td>10</td>\n",
       "      <td>-9999</td>\n",
       "      <td>rain</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>2</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>[{'layer': '950mb', 'rh': 11}, {'layer': '900m...</td>\n",
       "      <td>[{'layer': '950mb', 'direction': 195, 'speed':...</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>10</td>\n",
       "      <td>-9999</td>\n",
       "      <td>rain</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>[{'layer': '950mb', 'rh': 11}, {'layer': '900m...</td>\n",
       "      <td>[{'layer': '950mb', 'direction': 180, 'speed':...</td>\n",
       "      <td>27</td>\n",
       "      <td>-1</td>\n",
       "      <td>10</td>\n",
       "      <td>-9999</td>\n",
       "      <td>rain</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>2</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>[{'layer': '950mb', 'rh': 11}, {'layer': '900m...</td>\n",
       "      <td>[{'layer': '950mb', 'direction': 180, 'speed':...</td>\n",
       "      <td>27</td>\n",
       "      <td>-1</td>\n",
       "      <td>11</td>\n",
       "      <td>-9999</td>\n",
       "      <td>rain</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>3</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>-9999</td>\n",
       "      <td>[{'layer': '950mb', 'rh': 13}, {'layer': '900m...</td>\n",
       "      <td>[{'layer': '950mb', 'direction': 185, 'speed':...</td>\n",
       "      <td>27</td>\n",
       "      <td>-1</td>\n",
       "      <td>11</td>\n",
       "      <td>-9999</td>\n",
       "      <td>rain</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>185</td>\n",
       "      <td>3</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rh_950mb  rh_900mb  rh_850mb  rh_800mb  rh_750mb  rh_700mb  rh_650mb  \\\n",
       "0        10        10        11        11        12        13        12   \n",
       "1        11        12        12        12        12        12        11   \n",
       "2        11        12        12        12        13        14        14   \n",
       "3        11        12        11        11        13        15        16   \n",
       "4        13        12        11        11        13        15        15   \n",
       "\n",
       "   rh_600mb  rh_550mb  rh_500mb  rh_450mb  rh_400mb  rh_350mb  rh_300mb  \\\n",
       "0         9         8        10        15        15        16        16   \n",
       "1        10         8         9        12        15        16        16   \n",
       "2        13        10         7        12        12        10        15   \n",
       "3        15         9         6         4         5        14        16   \n",
       "4        15        13         6         4         6        10         6   \n",
       "\n",
       "   rh_250mb  rh_200mb  index  timepoint  cloudcover  highcloud  midcloud  \\\n",
       "0        12         9      0          3           8      -9999     -9999   \n",
       "1        15        13      1          6           9      -9999     -9999   \n",
       "2        16        15      2          9           9      -9999     -9999   \n",
       "3        16        10      3         12           7      -9999     -9999   \n",
       "4         4         6      4         15           6      -9999     -9999   \n",
       "\n",
       "   lowcloud                                         rh_profile  \\\n",
       "0     -9999  [{'layer': '950mb', 'rh': 10}, {'layer': '900m...   \n",
       "1     -9999  [{'layer': '950mb', 'rh': 11}, {'layer': '900m...   \n",
       "2     -9999  [{'layer': '950mb', 'rh': 11}, {'layer': '900m...   \n",
       "3     -9999  [{'layer': '950mb', 'rh': 11}, {'layer': '900m...   \n",
       "4     -9999  [{'layer': '950mb', 'rh': 13}, {'layer': '900m...   \n",
       "\n",
       "                                        wind_profile  temp2m  lifted_index  \\\n",
       "0  [{'layer': '950mb', 'direction': 175, 'speed':...      27            -4   \n",
       "1  [{'layer': '950mb', 'direction': 195, 'speed':...      26            -1   \n",
       "2  [{'layer': '950mb', 'direction': 180, 'speed':...      27            -1   \n",
       "3  [{'layer': '950mb', 'direction': 180, 'speed':...      27            -1   \n",
       "4  [{'layer': '950mb', 'direction': 185, 'speed':...      27            -1   \n",
       "\n",
       "   rh2m  msl_pressure prec_type  prec_amount  snow_depth  wind10m.direction  \\\n",
       "0    10         -9999      rain            2           0                150   \n",
       "1    10         -9999      rain            2           0                160   \n",
       "2    10         -9999      rain            3           0                180   \n",
       "3    11         -9999      rain            3           0                180   \n",
       "4    11         -9999      rain            3           0                185   \n",
       "\n",
       "   wind10m.speed country  \n",
       "0              2     usa  \n",
       "1              1     usa  \n",
       "2              2     usa  \n",
       "3              3     usa  \n",
       "4              3     usa  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clima.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "malformed node or string: [{'layer': '950mb', 'direction': 175, 'speed': 2}, {'layer': '900mb', 'direction': 180, 'speed': 2}, {'layer': '850mb', 'direction': 165, 'speed': 2}, {'layer': '800mb', 'direction': 125, 'speed': 2}, {'layer': '750mb', 'direction': 95, 'speed': 2}, {'layer': '700mb', 'direction': 85, 'speed': 3}, {'layer': '650mb', 'direction': 85, 'speed': 3}, {'layer': '600mb', 'direction': 80, 'speed': 4}, {'layer': '550mb', 'direction': 65, 'speed': 4}, {'layer': '500mb', 'direction': 45, 'speed': 5}, {'layer': '450mb', 'direction': 80, 'speed': 3}, {'layer': '400mb', 'direction': 100, 'speed': 4}, {'layer': '350mb', 'direction': 105, 'speed': 4}, {'layer': '300mb', 'direction': 110, 'speed': 4}, {'layer': '250mb', 'direction': 110, 'speed': 5}, {'layer': '200mb', 'direction': 115, 'speed': 5}]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/66/3gn2x5sj3tlfxjp4wp1zg9n00000gn/T/ipykernel_6231/3886925675.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#import ast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf_clima\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'wind_profile'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mdf_clima\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'wind_profile'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mliteral_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# una vez que tengamos la columna cambiada, una fantasía de Pandas es que si hago un apply sobre una columna cuyos valores son diccionarios o listas nos va a genererar una columna con los valores de los diccionarios o listas. Donde cada columna será key del diccionario o cada elemento de la lista.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4769\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4770\u001b[0m         \"\"\"\n\u001b[0;32m-> 4771\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4773\u001b[0m     def _reduce(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0;31m# self.f is Callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1154\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1156\u001b[0;31m                 mapped = lib.map_infer(\n\u001b[0m\u001b[1;32m   1157\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/ast.py\u001b[0m in \u001b[0;36mliteral_eval\u001b[0;34m(node_or_string)\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mleft\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_convert_signed_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_or_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/ast.py\u001b[0m in \u001b[0;36m_convert\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mleft\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_convert_signed_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_or_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/ast.py\u001b[0m in \u001b[0;36m_convert_signed_num\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0moperand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_convert_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConstant\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/ast.py\u001b[0m in \u001b[0;36m_convert_num\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_convert_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConstant\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomplex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0m_raise_malformed_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_convert_signed_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/ast.py\u001b[0m in \u001b[0;36m_raise_malformed_node\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mnode_or_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode_or_string\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_raise_malformed_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'malformed node or string: {node!r}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_convert_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConstant\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomplex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: malformed node or string: [{'layer': '950mb', 'direction': 175, 'speed': 2}, {'layer': '900mb', 'direction': 180, 'speed': 2}, {'layer': '850mb', 'direction': 165, 'speed': 2}, {'layer': '800mb', 'direction': 125, 'speed': 2}, {'layer': '750mb', 'direction': 95, 'speed': 2}, {'layer': '700mb', 'direction': 85, 'speed': 3}, {'layer': '650mb', 'direction': 85, 'speed': 3}, {'layer': '600mb', 'direction': 80, 'speed': 4}, {'layer': '550mb', 'direction': 65, 'speed': 4}, {'layer': '500mb', 'direction': 45, 'speed': 5}, {'layer': '450mb', 'direction': 80, 'speed': 3}, {'layer': '400mb', 'direction': 100, 'speed': 4}, {'layer': '350mb', 'direction': 105, 'speed': 4}, {'layer': '300mb', 'direction': 110, 'speed': 4}, {'layer': '250mb', 'direction': 110, 'speed': 5}, {'layer': '200mb', 'direction': 115, 'speed': 5}]"
     ]
    }
   ],
   "source": [
    "#import ast\n",
    "\n",
    "df_clima['wind_profile']= df_clima['wind_profile'].apply(ast.literal_eval)\n",
    "\n",
    "# una vez que tengamos la columna cambiada, una fantasía de Pandas es que si hago un apply sobre una columna cuyos valores son diccionarios o listas nos va a genererar una columna con los valores de los diccionarios o listas. Donde cada columna será key del diccionario o cada elemento de la lista. \n",
    "\n",
    "\n",
    "y = df_clima['wind_profile'].apply(pd.Series)\n",
    "\n",
    "\n",
    "# nos creamos un dataframe nuevo con el resultado de la información de una de las columnas separadas por columnas. Esto nos va a devolver un dataframe donde cada fila será una celda del dataframe anterior. \n",
    "#x = df_clima['rh_profile'].apply(pd.Series) \n",
    "\n",
    "# ¿Qué es lo que ocurre cuando hacemos esto?\n",
    "# Nos ha creado tantas columnas como valores tuvieramos en la lista. Donde columna es, en este caso, un diccionario (porque nuestra lista esta compuesta por distintos diccionarios)\n",
    "\n",
    "# Ok, hemos conseguido desempaquetar la información de la lista en distintas columnas. Ahora tenemos que despempaquetar la información de los diccionarios en distintas columnas. En este caso, lo que querremos es que las key de los diccionarios sean los nombres de las columnas y los values los valores de las celdas del dataframe. Volveremos a seguir entonces la misma lógica que antes con el apply, pero en este caso necesitamos hacerlo para todo el dataframe (que es x): \n",
    "\n",
    "# Por eso empezamos con un for para iterar por cada una de las columnas. \n",
    "for i in range(len(y.columns)): \n",
    "\n",
    "    # aplicamos el apply,extraemos el valore de la key \"layer\" y lo almacenamos en una variable que convertimos a string \n",
    "    nombre = \"winddirection_\" + str(y[i].apply(pd.Series)[\"layer\"][0]) \n",
    "\n",
    "    # hacemos lo mismo con una variable que se llame valores para \"guardar\" los valores de la celda\n",
    "    valores = list(y[i].apply(pd.Series)[\"direction\"])\n",
    "\n",
    "    # usamos el método insert de los dataframes para ir añadiendo esta información a el dataframe con la información del clima. \n",
    "    df_clima.insert(i, nombre, valores)\n",
    "\n",
    "# una vez que hayamos hecho esto para las dos columnas ya podremos hacer el gropuby para después unir toda la información. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'base (Python 3.9.7)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "rh[0].apply(pd.Series)\n",
    "#nombre de la columna es layer que es la key de la columna 0\n",
    "#mientras la columna rh son los valores de la key rh "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'base (Python 3.9.7)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'base (Python 3.9.7)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "rh.head(1)\n",
    "\n",
    "for i in range(len(rh.columns)): \n",
    "    rh[i].apply(pd.Series)\n",
    "    #print (x)\n",
    "\n",
    "    # aplicamos el apply,extraemos el valore de la key \"layer\" y lo almacenamos en una variable que convertimos a string \n",
    "    nombre = \"rh_\" + str(rh[i].apply(pd.Series)[\"layer\"][0]) \n",
    "    print(nombre)\n",
    "    # hacemos lo mismo con una variable que se llame valores para \"guardar\" los valores de la celda\n",
    "    valores = list(rh[i].apply(pd.Series)[\"rh\"] )\n",
    "\n",
    "    # usamos el método insert de los dataframes para ir añadiendo esta información a el dataframe con la información del clima. \n",
    "    df_clima.insert(i, nombre, valores)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'base (Python 3.9.7)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'base (Python 3.9.7)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'base (Python 3.9.7)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "df_clima.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'base (Python 3.9.7)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "651c3b7b3f466eb030aa737f279c846be4db9cba49a2f229278cab5e41121ed5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
